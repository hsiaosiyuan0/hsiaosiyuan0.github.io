<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hsiaosiyuan</title>
    <link>http://example.org/</link>
    <description>Recent content on hsiaosiyuan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Aug 2020 00:00:00 +0800</lastBuildDate><atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Decorator has different implementations in babel and tsc</title>
      <link>http://example.org/typescript/decorator/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/typescript/decorator/</guid>
      <description>Decorator has different implementations in babel and tsc Assuming we have below code:
import { Controller, Get } from &amp;#39;@nestjs/common&amp;#39;; import { AppService } from &amp;#39;./app.service&amp;#39;; @Controller() export class AppController { constructor(private readonly appService: AppService) {} @Get() getHello(): string { return this.appService.getHello(); } } for tsc with the option emitDecoratorMetadata is turned on, above code will be translated into：
import { Controller, Get } from &amp;#39;@nestjs/common&amp;#39;; import { AppService } from &amp;#39;.</description>
    </item>
    
    <item>
      <title>V8 调试</title>
      <link>http://example.org/v8/debug-v8-in-vscode/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/v8/debug-v8-in-vscode/</guid>
      <description>背景 背景有2：
  虽然目前存在各式的 JavaScript 引擎，但是由于其优异的性能表现 V8 已经成为相对的标准。
在深入学习 JavaScript 语言的过程中，除了需要对 语言标准 进行了解掌握，引擎作为对语言标准的实现，了解学习引擎内部的执行机理则是另一个更为立体的学习语言的方式。
学习引擎内部机理，直接阅读源码的方式显得过于抽象，如果可以将引擎构建运行起来，并且可以对其进行断点调试，会使学习的过程变得生动有趣。
  在 node-debugger 中基于我对 debugger 的理解画了一个通用形式的构架图，希望可以将图中的内容对应到 v8 的实现细节中
  接下来内容，就是对如何在 VSCode 中对 V8 引擎进行断点调试的过程的记录。
获取源码 可以参照 V8 官网中的章节 Building V8 from source 来获取并从源码构建 V8。V8 作为 Chromium 项目的一部分，其构建方式都是沿用的与 Chromium 相同的。
按照官网记录的步骤，需要先配置构建工具 depot_tools 并利用 gclient sync 来同步项目的依赖，如果不是为了向 V8 贡献源码、只是以学习为目的的话，整个构建的过程显得相对繁琐，并且构建出的内容在 Windows 和 MacOS 下进行断点调试有存在问题。
为了方便代码的获取和调试，我在 v8-cmake 项目的基础上加入了 VSCode 容器调试相关的配置，称之为了 v8-cmake-vscode。
v8-cmake-vscode 包含两个部分的内容：
  针对 V8 的 CMake 配置。V8 默认的构建配置对主流的编辑器比如 VSCode 或者 CLion 没有比较好的支持</description>
    </item>
    
    <item>
      <title>Lifetime</title>
      <link>http://example.org/rust/lifetime/</link>
      <pubDate>Wed, 19 Aug 2020 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/rust/lifetime/</guid>
      <description>Lifetime Rust 的绝大部分语法都非常简洁、易于理解，而其为了保证内存安全引入的 lifetime 概念则对大部分人来说是第一次接触
变量的作用域 孤零零的「作用域」是不明确的，所以这里的标题是「变量的作用域」，因为作用域的概念，指的就是一个区间、在改区间内，某个变量是可用的。这里「区间」的定义不同，又分为静态作用域或者动态作用域，更多的可以参考 闭包的作用
Rust 受到 OCaml 这样函数式语言的影响，对变量的 Scope 定义有着一些相似的理解，比如在 OCaml 中通过下面的方式定义变量：
let add_vect v1 v2 = let len = min (Array.length v1) (Array.length v2) in // ---------+-- s1 let res = Array.make len 0.0 in // ---+- s2 | for i = 0 to len - 1 do // | | res.(i) &amp;lt;- v1.(i) +. v2.(i) // | | done; // ---+-----+ 上面这段代码，定义了一个名为 add_vect 的函数，该函数具有两个形参：v1 v2，let a in b 语句表示定义了变量 a，它的 lifetime（可用期）在随后的（in 之后）的语句内，换句话说 in 之后出现了一个新的 scope，在这个 scope 中 a 是可用的</description>
    </item>
    
    <item>
      <title>使用 Rust 重写 ternjs</title>
      <link>http://example.org/static-analysis/ternjs/</link>
      <pubDate>Tue, 04 Aug 2020 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/static-analysis/ternjs/</guid>
      <description>使用 Rust 重写 ternjs ternjs 是一个完全使用 JavaScript 编写的针对 JavaScript 的代码静态分析工具。它是我目前发现的用来入门静态分析最好的项目了：
 没有复杂的流程分析 推导的算法简单清晰 相对详实的文档 完全使用 JavaScript 实现  静态分析程序的核心的就是其使用的分析算法，传统的对静态语言进行静态分析的算法、有比较固定的格式，即结合数据和控制流程的分析，这样的方式对于动态语言 JavaScript 来说或许不是非常合适。ternjs 作者另辟蹊径，采用一种非常简单精巧的算法，也能达到不错的分析结果，其分析结果虽然不能完全用作 Lint 工具，但是作为类型提示或者代码补全工具却是绰绰有余
另外这还是一个价值 16,535 欧元（2013年左右）的算法1，实在没有理由不收入囊中
学习方式 因为我们知道这是一个代码静态分析工具，就像我们看程序一般从 main 开始尝试梳理脉络一样，我们可以从 infer 部分开始看。在 infer 的介绍中，作者提到了一些实现细节，比如需要一个 error-tolerant parser 以及 The syntax tree format 是参考的 Mozilla parser API
上面这些基本都是轻车熟路了：先得到程序结构的抽象描述，然后基于这个抽象结果做文章。做文章所需的推导算法，作者已经给出了比较详细的描述，既然有了算法的描述，就不必傻乎乎的直接去看代码了，按照这个算法先撸一版出来，有问题再去看源码，毕竟是重写而不是抄写
假如从头开始撸的话，对于已经是编写 Recursive Descent Parser 的老司机来说未免显得在准备工作上花费了太多时间了，所以解析器的工作，我们直接选用 swc 了，另外介绍一下从 swc 的 slack 问来的其名字的含义：
 Speedy Web Compiler. It’s fast, and it compiles transpiles (js and ts) code to a web-consumable form.</description>
    </item>
    
    <item>
      <title>midway 分析</title>
      <link>http://example.org/oop/ioc/</link>
      <pubDate>Sun, 18 Aug 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/oop/ioc/</guid>
      <description>midway 分析 按目前项目主页的描述，当前默认分支是 serverless，该分支主要提供跨平台的 Serverless 能力，这部分工作是在原有的全栈框架的基础上，抽象不同 Serverless 平台的差异，对外提供相对一致的 Serverless 接口
原有的全栈框架实现在 master 分支，接下来将主要分析 master 分支的内容
master 分支中的 README 概况了自身的功能：
 Midway is a Node.js Web framework written by typescript, which uses the IoC injection mechanism to decouple the business logic of the application and make the development of large Node.js application easier and more natural.
 主要特点为：
 使用 TypeScript 编写 实现了 IoC 设计理念，方便模块间的解耦 基于 “框架的框架” egg 做了一些调整  目录结构 使用注解控制路由 controller 和 service 测试方式   脚手架以及编辑器增强  按照上面罗列的功能点，应该只有 IoC 是一个比较新的概念，除了 IoC 应该都是和 mug 重叠的功能。所以下面将讨论一下 midway 的 IoC 实现</description>
    </item>
    
    <item>
      <title>闭包的作用</title>
      <link>http://example.org/javascript/the-duty-of-closure/</link>
      <pubDate>Tue, 06 Aug 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/javascript/the-duty-of-closure/</guid>
      <description>闭包的作用 这里我们将主要关注闭包的作用。至于到底什么是闭包，可以参考 闭包。
如果被问到「闭包有什么作用？」想必有同学首先会想到「模拟私有变量」，又或者「在回调中有时会用到」，又或者最接近正确答案的「用于捕获变量」等等诸如此类。
这些回答显然都是正确的，不过它们并不是「闭包的作用」，而是闭包的一些具体的使用场景。其实如果被问到「闭包的作用」，那么这个问题本身就模棱两可，问一个东西的作用时，需要限定它的适用场景，把它放到一个前置环境下，再问它的作用。好比我问你平口起子的作用，你如果回答用它来在课桌上划三八线，我觉得也未尝不可。
而如果什么都不限定的问一句「平口起子的作用是什么」，那么我们从「平口起子最初是为什么被制造的」这个点来回来，才算是答其所问了。同样的，如果被问到「闭包有什么作用」，那么回答为什么需要闭包，才是答其所问，而不是闭包都能干什么。
当明白了问题之后，就已经成功了一大步。
作用域 首先我们知道编程语言中有一个「作用域」的概念，那么为什么是作用域呢？作用域就是程序中的「一段范围」在这个范围之内，某些变量是有效的。那么为什么要提出这个概念呢？没有作用域就不能编程吗？当然不是，没有作用域也是可以编程的，我们知道机器语言就没有作用域的概念，我曾经见过有前辈直接使用机器码编写出音乐播放器。
那么既然没有作用域也能编程，为什么要引入这个概念呢？这是因为高级编程语言中要尽量的提供丰富地表达程序的能力，因此提出了变量名的概念，而编程中的词汇是相对匮乏的，毕竟编程是一定程度上的对现实抽象的内容。想象一下，如果程序中对于同一个变量名只能使用一次，那么必定是一个噩梦，比如我们在写循环的时候经常使用 i，这下好了，程序中只能出现一个 i，其余都得是 i1 i2 ... iN 这样了。
有了作用域之后，我们在每个作用域中都能使用 i 了，这样就使得大家的词汇量得到了解放，也一定程序上使得程序表达更加简洁清晰，否则因为是程序中第 100 个循环就使用变量 i100 多少会让人感到有点傻。
一段范围 注意我们在介绍作用域中提到的：作用域就是程序中的「一段范围」在这个范围之内，某些变量是有效的。这个一段范围，在现有的编程语言实现中具有两种不同的解释：
 静态作用域，又称为词法作用域 动态作用域  静态作用域 在具有静态作用域的语言中，它们对「一段范围」的解释是，代码中的一段范围。换句话说，变量的作用域是直接体现在代码中的、即静态的；在解析阶段就可以确定的、即词法的。静态作用域的好处就是，通过阅读代码，我们和解析程序就能够确定一个变量的作用域，当然就很方便理解了。
动态作用域 在那些使用动态作用域的语言中，它们对「一段范围」的解释是，程序执行中的某个时间点。换句话说，变量的作用域是又程序运行阶段的行为确定的，是不可预测的，因此在人肉确定变量的作用域时会花费一些精力。
静态作用域的例子： // 一段用于演示静态作用域的 C 语言程序 #include&amp;lt;stdio.h&amp;gt; int x = 10; int f() { return x; } int g() { int x = 20; return f(); } int main() { printf(&amp;#34;%d&amp;#34;, g()); printf(&amp;#34;\n&amp;#34;); return 0; } 结果打印 10</description>
    </item>
    
    <item>
      <title>Generator Function</title>
      <link>http://example.org/javascript/generator-function/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/javascript/generator-function/</guid>
      <description>Generator Function 目前在我的玩具 JS 引擎 naive 中还没有实现 Generator，所以这篇除了可以当做是预先调研之外，也可以作为稍微深入到 Generator 实现细节的介绍。
普通函数 由于 Generator Function 和普通函数长得太像了，所以先回顾一下普通函数实现细节。
我们知道在 C 语言中函数最终体现为代码段中的一段内容，该段内容就是函数体内容对应的机器码，而函数名则为该段代码的首地址，在编译期间会被替换处理。
但是在学习 JS 的时候，并不是每个地方都能以 C 语言来参考，这里把 C 换成任何其他语言也说得通；可以在一些问题发生的时候，使用已经掌握的知识来参考联想，但是最终还是要回归到该语言自身的技术规格文档中。
在 JS 中，函数作为一个对象，该对象包含了以下几个内容：
 形参信息 函数体内容所对应的字节码 与之关联的闭包  当我们调用函数的时候，引擎就会做以下的事情：
 创建一个表示调用信息的对象 CallInfo 将第一步创建的对象添加到调用栈中 引擎根据调用栈顶层的调用信息继续执行  而 CallInfo，包含下面的内容：
 调用的函数对象 PC，表示接下来需要被执行的字节码的地址 this 对象，用于在执行 THIS 指令的时候取得对应的对象  另外 JS 引擎在运行时会用到两个栈结构，一个作为调用栈，一个作为操作数栈。我们上面介绍的是调用栈，而操作数栈用于存放指令执行时所用到的操作数，包括局部变量和临时变量。
生成器函数 我们来看一个典型的生成器函数的例子：
function* idMaker() { var index = 0; while(true) yield index++; } 想必大家第一次接触到这个语法的时候一头雾水，因为一直以来 while(true){ /* no break or return */ } 这样的形式，直接告诉我们该循环为一个死循环。恰好上面的例子中，while 语句中也没有 break 和 return，如果是死循环，那么这段代码肯定就失去意义了，如果不是死循环，又打破了我们之前的认知。</description>
    </item>
    
    <item>
      <title>Unicode 和 BMP</title>
      <link>http://example.org/javascript/javascript-internal-encoding/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/javascript/javascript-internal-encoding/</guid>
      <description>Unicode 和 BMP Unicode 通过一个确切的名称以及一个整数 (这个整数被叫做该字符的码位 code point) 来标识不同的字符。比如，字符 © 的名称是 “版权标识 (copyright sign)”、它的 code point 是 U+00A9 &amp;ndash; 0xA9 (十进制的 169)。
Unicode 的编码空间被分离成了 17 个平面，每个平面包含 2^16 (十进制 65,536 即十六进制 0xFFFF) 个码位 (code point)。其中的一些码位尚未被分配到字符，还有一些码位作为私有用途，还有一些永久保留、不存放任何字符 (U+D800到U+DFFF)。每个平面中的码位 (code point) 的取值范围在 xy0000 ~ xyFFFF，xy 表示的是该码位所属的平面，上面提到编码空间被分离成了 17 个平面，这里的 xy 就是这 17 个平面的编号就的十六进制表示，即 00 ~ 10。
第一个平面 (即上面的 xy 为 00) 被称为 基本多语言平面 (Basic Multilingual Plane ) 简称 BMP，它所包含的码位范围是 U+0000 ~ U+FFFF，这些都是使用频率最高的字符。
剩余的十六个平面 (U+100000 ~ U+10FFFF) 被称为 补充平面 (supplementary planes or astral planes)。这里将不继续讨论它们，只要记住字符分为 BMP 字符和 非-BMP (non-BMP) 字符，后者又被称为补充平面。</description>
    </item>
    
    <item>
      <title>闭包</title>
      <link>http://example.org/javascript/closure/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/javascript/closure/</guid>
      <description>闭包 很多分享都会解释什么是闭包，不得不说大都管中窥豹。比如某 star 1k 的项目中描述
 所有函数都是闭包
 是不恰当的。但是在有 1k stars 的情况下，居然没有 issue 指出其中的错误。
首先必须说，闭包就取名和中文翻译而言，在你正在理解了它之后，会发现它恰到好处。如果你还觉得命名很奇怪，那么就说明你并不理解它。
就如同它的名字描述的一般，闭包表示的是一个封闭的内存空间。每个函数被创建的时候，都有一个与之关联的闭包。在了解闭包的使用场景之前，先看下面一个例子：
function f() { var i = 0; console.log(i); } f(); 这段代码非常简单。我们知道一旦 f 执行完毕，那么它本次执行的栈上的数据将会被释放，所以每次调用结束后，栈上的 i 都会被及时的释放。
再来看另一个例子：
function f() { var i = 0; return function () { // f1  console.log(i); } } var ff = f(); ff(); 和第一个例子一样，这段代码同样会打印 0。但是这似乎打破了我们第一个例子的总结，按照第一个例子的说法，f 运行结束后，本次调用的栈上的 i 应该被释放掉了。但是我们随后调用返回的匿名函数，发现并没有报错，这就归功于闭包。
每个函数被创建的时候，都会有一个与之关联的闭包被同时创建。在新创建的函数内部，如果引用了外部作用域中的变量，那么这些变量都会被添加到该函数的闭包中。
注意上面代码的注释，为了方便描述，我们将匿名函数取名为 f1。当 f 被调用的时候，f1 被创建，同时与之关联的闭包也被创建。由于 f1 内部引用了位于其作用域之外的、f 作用域中的变量 i，因此 f 作用域中的 i 被拷贝到了 f1 的闭包中。这就解释了，为什么 f 执行完成之后，调用 f1 依然可以打印 0。</description>
    </item>
    
    <item>
      <title>解析 JSON 的成本</title>
      <link>http://example.org/javascript/the-cost-of-json-parsing/</link>
      <pubDate>Wed, 26 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/javascript/the-cost-of-json-parsing/</guid>
      <description>解析 JSON 的成本 今天看到大神 @mathias 的推，说如果程序中使用 JSON 格式来保存大量配置信息的时候，可以通过形如 JSON.parse(&#39;{&amp;quot;foo&amp;quot;:42,&amp;quot;bar&amp;quot;:1337}&#39;); 的方式来加速程序的启动。
我了解后发现，v8 为了加速对 JS 程序的解析，将 One-pass parsing 拆分为了 Preparsing 和 Lazy parsing。v8 会将函数的函数体编译为字节码，而在 Preparsing 中，不会将所有函数的函数体都一股脑地编译为字节码，而是将对非 PIFE 的函数的函数体的编译动作延迟到程序中第一次使用它们的时候，这就是 Lazy parsing。
虽然 Preparsing 中不会对函数体进一步处理，它还是会扫描整个 JS 文件，保证函数体中的内容是符合语法定义的。所以如果在程序中直接使用对象字面量来存放配置信息，比如：
function start() { let cfg = { foo: 42, bar: 1337 }; // consume cfg } start() 会对对象字面量进行两次解析，一次发生在 Preparsing 中，目的是为了保证其语法正确性；另一次发生在 Lazy parsing 中，因为 start 函数被调用了，于是需要将其函数体进行编译，此时会解析第二次。
而如果将程序改成:
function start() { let cfg = JSON.parse(&amp;#39;{&amp;#34;foo&amp;#34;:42,&amp;#34;bar&amp;#34;:1337}&amp;#39;); // consume cfg } start() 我们直接使用了对象字面量对应的字符串形式，然后使用 JSON.</description>
    </item>
    
    <item>
      <title>汇编语言学习小结</title>
      <link>http://example.org/assembly/learning-assembly-lang/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/assembly/learning-assembly-lang/</guid>
      <description>汇编语言学习小结 学习汇编语言书「guide-to-assembly-language-programming-in-linux」的收获:
 了解汇编语言的语法 了解 CPU 和 内存的基本结构 栈及其相关操作 了解汇编语言层面如何进行 Procedure 调用，包括传参和返回值和返回点如何处理 了解汇编语言和 C 语言如何相互调用，以及 C 语言是如何编译成汇编语言  汇编语言的语法 汇编语言的语法包括预处理和指令生成两种，预处理部分在汇编的预处理阶段被处理，而指令生成部分则会在编译阶段生成具体的指令。 比如预处理阶段的 macro 和 %define 以及指令生成阶段的 add AX, 1。
对于指令生成的语法，都是每一行对应一条指令，且语法形式为 opode operand1, operand2, ... 即操作码接操作数的形式。
了解 CPU 和内存的基本结构 CPU 由各种运算电路以及寄存器组成。运算电路负责实际的运算，而寄存器用于存放参数，临时结果，最终结果。寄存器分为通用寄存器和特定用途寄存器。
特定用途寄存器又大致分为： 段寄存器，标志寄存器和指令指针寄存器，等。对于 EBP 和 ESP 这两个寄存，有时又被称为特殊通用寄存器，这是因为在进行栈的相关操作时这两个寄存器会有特殊用途。所谓“通用”指的是，该寄存器可以作为计算或者存放临时结果的寄存器，而特殊寄存器则被限定了其用途，比如指令指针寄存器，只可以用于存放接下来的指令的位置。
之所以 ESP 和 EBP 被称为通用寄存器就是因为，这两个寄存器也是可以在计算时用于存放临时结果的，只不过在栈相关操作时，为了方便将他们的功能基于约定地限定了。
对于内存的基本结构而言，CPU 并不能够直接访问内存上的数据，而是要通过地址总线，数据总线和控制总线，来指挥内存芯片来读取或者写入内存数据。由于内存以及 CPU 的设计结构限制，会有存在内存上的数据需要进行对齐的要求，如前所述，该要求并不是绝对的。数据对齐一般都是有编译器自动完成的，这在 C 语言中就涉及到数据 padding。
栈及其相关操作 栈是一个后进先出的结构，并且向低地址方向增长，栈中只会存放 word 和 double words 长度的元素，不会单独存放单个字节。TOS 指向的是栈顶元素的最低字节，栈中元素被 pop 后，只是将 TOS 向高地址方向进行移动，以此达到元素被移出的效果。移出元素的内存中的数据则实在下一次的入栈操作时被覆写。
了解 Procedure 调用细节 过程调用时的参数可以通过寄存器或者栈进行传递。使用寄存器和栈个有利弊。使用寄存器能获取更高的性能，这是因为减少了内存操作，操作数直接存在于寄存器中了。使用寄存器的弊端就是，寄存器数量是有限的，所以主要还是应该将它们用于计算。使用栈传递的参数的好处就是可以将原本用于传参的寄存器解放出来，用于计算，弊端就是在涉及到具体的计算时，需要将数据从栈中载入寄存器。</description>
    </item>
    
    <item>
      <title>Cluster 模块分析</title>
      <link>http://example.org/node/the-cluster-module/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/node/the-cluster-module/</guid>
      <description>Cluster 模块分析  Cluster 模块分析  预备工作 发现问题 问题1. work 进程的创建 问题2. listen 方法 问题3. 不退出 问题4. 处理请求    预备工作 分析的是从 node 源码的角度进行的，所以需要先配置源码的调试环境。
需要准备的内容为:
 node 源码 CLion  node 源码的获取，通过以下命令行:
git clone https://github.com/nodejs/node.git # 本文针对的版本 git checkout tags/v11.6.0 获取了 node 源码之后，需要在 CLion 中导入项目，详细可以参考此文 使用 cLion 调试 node.js 源码。
上文中提到的源码编译指令为:
make -C out BUILDTYPE=Debug -j 4 -j 4 的意义是同时执行的任务数，一般设定为 CPU 核数，可以通过下面指令获得 CPU 核数:
[ $(uname) = &amp;#39;Darwin&amp;#39; ] &amp;amp;&amp;amp; sysctl -n hw.</description>
    </item>
    
    <item>
      <title>Parsing in practice</title>
      <link>http://example.org/work/parsing-in-practice/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/work/parsing-in-practice/</guid>
      <description>Parsing in practice 现在工作中的项目是一个数据展示类的项目，主要负责将后端分析过的数据，通过 charts 显示到页面中。项目是前后端分离的，它构架是：
前端页面 -&amp;gt; nodejs 中间层 -&amp;gt; java 服务 比如现在页面中需要显示三个指标：访客数(UV)，支付订单数(PAY_ORDER_CNT)，退货率
对于前两个指标，要得到它们的数值非常简单，就是把括号中的字母内容作为 key 提交给接口服务，接口服务就会返回 key 所对应的数值，前端得到数据直接显示即可。我们可以暂且把这种可以直接由 key 取到内容的指标成为 &amp;ldquo;简单指标&amp;rdquo;，并且由于接口不支持多个 key 同时查询，所以每个简单指标必须独立为一个接口请求。
对于退货率这个指标，我们可以称之为 &amp;ldquo;复合指标&amp;rdquo;，它是由几个简单指标计算得来的，比如这个退货率，它在后端提供的文档中描述的表达式是:
RETURN_ORDER_CNT / (RETURN_ORDER_CNT + SUB_PAY_ORDER_CNT) 这个表达式中涉及的两个简单指标是：退货订单数(RETURN_ORDER_CNT) 和 正向支付订单数(SUB_PAY_ORDER_CNT)。然而，在实际操作中，会有各种简单指标进行运算组合的复合指标，而且由于复合指标的需求是会不断更改和增加的，所以如果只是针对每个复合指标不断写子处理程序的话，那么工作量以及维护成本将会很高。对于复合指标的计算，本应该放在服务端运行，由接口直接提供计算结果，但是由于它们机械繁琐的工作量，后端没人愿意做。
毕竟到了前端就没人可以说理去了，总不能让用户自己来算复合指标吧。这时我们的编译技术排上了用场。
首先复合指标都是一些简单的数学表达式，把这些复合指标的计算表达式形容成 DSL 也不过份吧。
要计算复合指标，只需要分两步：
 分别请求计算复合指标所需的每个简单指标的值 对表达式进行求值  好在这个 DSL 非常的简单，只要处理表达式的解，而且只有双目运算，就省去了结合性的考虑，只要处理运算符优先级就可以了。
因为只是处理运算符的优先级，利用 Shunting Yard Algorithm 就好了。将表达式由 中缀(infix) 转换成 后缀(postfix) 形式，保存在一个栈中，
RETURN_ORDER_CNT/(RETURN_ORDER_CNT+SUB_PAY_ORDER_CNT) 就被处理成了
// 栈底 -&amp;gt; 栈顶 RETURN_ORDER_CNT RETURN_ORDER_CNT SUB_PAY_ORDER_CNT + / 然后逐个弹出栈中的内容，如果是运算符，就分别弹出两个操作数，如果操作数又是运算符，那么就递归调用，如果操作数是标识符，那么就带入之前的简单指标请求的结果，最后根据不同的运算符来对两个操作数进行运算。
这是一个在线的预览 复合指标计算，点击了 run 之后，打开 console 看下是否有没有通过的 assert 就可以了。</description>
    </item>
    
    <item>
      <title>The as-if rule</title>
      <link>http://example.org/cpp/the-as-if-rule/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/cpp/the-as-if-rule/</guid>
      <description>The as-if rule 之前了解过 CPP 编译器会有返回值优化「RVO, Return Value Optimization」功能。所以搜索了一下 C 编译器是否也具有该功能。
所谓 RVO，考虑下面的代码：
#include &amp;lt;iostream&amp;gt; struct C { C() {} C(const C&amp;amp;) { std::cout &amp;lt;&amp;lt; &amp;#34;A copy was made.\n&amp;#34;; } }; C f() { return C(); } int main() { std::cout &amp;lt;&amp;lt; &amp;#34;Hello World!\n&amp;#34;; C obj = f(); return 0; } 在函数 f 中，直接返回了栈上创建的 C 的实例。在未做优化的情况下，目标代码会将栈上的返回值数据拷贝给 caller；而在有了 RVO 的情况下，该拷贝操作可以被优化掉，即原本在 f 调用栈上创建的返回值，直接创建在 caller 的调用栈上，这样在 f 调用结束后，caller 可以直接使用返回值而不需要拷贝。
而 C/CPP 中的这些优化(包括 RVO)，都遵循了 as-if 原则，规则的细节可以参考 The as-if rule.</description>
    </item>
    
    <item>
      <title>WebSocket 协议 1-4 节</title>
      <link>http://example.org/websocket/websocket-1-4/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/websocket/websocket-1-4/</guid>
      <description>此文仅作为 RFC6455 的学习笔记。篇幅太长超过了简书的单篇最大长度，故分为两篇，此篇记录 1~4 节，其余见 WebSocket 协议 5~10 节;
1.1 背景知识 由于历史原因，在创建一个具有双向通信机制的 web 应用程序时，需要利用到 HTTP 轮询的方式。围绕轮询产生了 “短轮询” 和 “长轮询”。
短轮询 浏览器赋予了脚本网络通信的编程接口 XMLHttpRequest ，以及定时器接口 setTimeout 。因此，客户端脚本可以每隔一段时间就主动的向服务器发起请求，询问是否有新的信息产生：
 客户端向服务器发起一个请求，询问 “有新信息了吗” 服务端接收到客户端的请求，但是此时没有新的信息产生，于是直接回复 “没有”，并关闭链接 客户端知道了没有新的信息产生，那么就暂时什么都不做 间隔 5 秒钟之后，再次从步骤 1 开始循环执行  长轮询 使用短轮询的方式有一个缺点，由于客户端并不知道服务器端何时会产生新的消息，因此它只有每隔一段时间不停的向服务器询问 “有新信息了吗”。而长轮询的工作方式可以是这样：
 客户端向服务器发起一个请求，询问 “有新信息了吗” 服务器接收到客户端的请求，此时并没有新的信息产生，不过服务器保持这个链接，像是告诉客户端 “稍等”。于是直到有了新的信息产生，服务端将新的信息返回给客户端。 客户端接收到消息之后显示出来，并再次由步骤 1 开始循环执行  可以看到 “长轮询” 相较于 “短轮询” 可以减少大量无用的请求，并且客户端接收到新消息的时机将会有可能提前。
继续改进 我们知道 HTTP 协议在开发的时候，并不是为了双向通信程序准备的，起初的 web 的工作方式只是 “请求-返回” 就够了。
但是由于人们需要提高 web 应用程序的用户体验，以及 web 技术本身的便捷性 - 不需要另外的安装软件，使得浏览器也需要为脚本提供一个双向通信的功能，比如在浏览器中做一个 IM（Instant Message）应用或者游戏。</description>
    </item>
    
    <item>
      <title>WebSocket 协议 5-6 节</title>
      <link>http://example.org/websocket/websocket-5-6/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/websocket/websocket-5-6/</guid>
      <description>第 1~4 节在 WebSocket 协议 1~4 节;
5. 使用帧去组织数据 5.1 概览 在 WebSocket 协议中，数据的传输使用一连串的帧。为了使得中间件不至于混淆（比如代理服务器）以及为了第 10.3 节将讨论安全原因，客户端必须将要发送到服务端的帧进行掩码，掩码将在第 5.3 节详细讨论。（注意，不管 WebSocket 有没有运行在 TLS 之上，都必须有掩码操作）服务端一旦接收到没有进行掩码的帧的话，必须关闭连接。这种情况下，服务端可以发送一个关闭帧，包含一个状态码 1002（协议错误 protocol error），相关定义在 Section 7.4.1。服务端不必对发送到客户端的任何帧进行掩码。如果客户端接收到了服务端的掩码后的帧，客户端必须关闭连接。在这个情况下，客户端可以向服务器发送关闭帧，包含状态码 1002（协议错误 protocol error），相关定义在 Section 7.4.1。（这些规则可能在将来技术说明中没有严格要求）
基础帧协议通过操作码（opcode）定义了一个帧类型，一个有效负荷长度，以及特定的位置存放 “扩展数据 Extension data” 和 “应用数据 Application data”，扩展数据和应用数据合起来定义了 “有效负荷数据 Payload data”。某些数位和操作码是保留的，为了将来的使用。
在客户端和服务端完成了握手之后，以及任意一端发送的关闭帧（在第 5.5.1 节介绍）之前，客户端可以和服务端都可以在任何时间发送数据帧。
基础帧协议 这一节中将使用 ABNF 详细定义数据传输的格式。（注意，和这文档中的其他 ABNF 不同，这一节中 ABNF 操作的是一组数位。每一组数位的长度将以注释的形式存在。当数据在网络中传输时，最高有效位是在 ABNF 的最左边（大端序））。下面的文本图像可以给出关于帧的一个高层概览。如果下面的文本插图和后的 ABNF 描述发送冲突时，以插图为准。
 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued .</description>
    </item>
    
    <item>
      <title>为什么 PHP 不适合长时间运行</title>
      <link>http://example.org/php/why-php-is-not-good-for-long-time-running/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/php/why-php-is-not-good-for-long-time-running/</guid>
      <description>为什么 PHP 不适合长时间运行 首先需要先看下这篇 Reference Counting Basics 文章，该文章描述了引用计数的基本概念以及它是如何应用在 PHP 引擎中的。
通过阅读上文我们就知道，基于引用计数这种内存管理方式的语言在编写代码的时候，都有一个需要程序员来解决的问题，那就是避免循环引用 (circular reference)。
但是对于上了一定规模的程序而言，靠人脑是很难避免循环引用的。同样使用引用计数的语言比如 Objc，它是通过提供一些编程规范，比如 Advanced Memory Management Programming Guide，然后配以工具进行静态分析，帮助程序员来在程序运行前就发现可能的循环引用。
PHP 作为动态类型的语言，我想应该很难复用静态类型语言中的分析技术 (比如 Objc 中的)，来给程序员提供一个分析工具以发现潜在的循环引用。但是我想 PHP 团队之所以没有提供静态分析工具的另外一个主要原因就是 Reference Counting Basics 所说的：
 Fortunately, PHP will clean up this data structure at the end of the request, but before then, this is taking up valuable space in memory.
 PHP 作为一个 WEB 专门的语言，最常用的方式就是嵌入到 cgi 程序中，在请求结束时，会一次性的释放当次请求所占用的内存，以此避免存泄漏。 当然 Reference Counting Basics 也说了：
 This is especially problematic in long running scripts, such as daemons where the request basically never ends, or in large sets of unit tests</description>
    </item>
    
    <item>
      <title>大小端序</title>
      <link>http://example.org/os/endian/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/os/endian/</guid>
      <description>大端模式，是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中，这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放；
  小端模式，是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低，和我们的逻辑方法一致。
 比如现在有一块四个字节的内存，并且地址是从左往右递增的。为了方便，都置为 0
1000:1000 00 00 00 00 现有一个十六进制数 0x12345678，这个十六进制数刚好可以使用上面的那块内存去存放，因为它们都是 32bits。
大端序 如果是大端序，内存表现将会是这样
1000:1000 12 34 56 78 可以发现，12 是原十六进制数 0x12345678的高位，而这个 12 放在上面那块内存地址的最低单元中（因为前面说了，这块内存地址是从左往右递增的，所以左边是相对低位，右边是相对高位）。这就是这段话的意思
 大端模式，是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中
 小端序 如果是小端序，内存表现是这样的
1000:1000 78 56 34 12 可以发现，78 是原十六进制数 0x12345678的低位，而此时它也放在了最低的内存单元中，这就是这段话的意思
 小端模式，是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中
 另外，可以发现，大小端序对字节内容是没有影响的，12还是 12 并没有变成 21
另外，对于类似下面情形，一般为内存或者文件 dump 工具的输出内容，通常的阅读顺序是，从左往右、从上到下:
0AEC:0000 CD 20 FF 9F 00 9A EE FE-1D F0 4F 03 50 05 8A 03 0AEC:0010 50 05 17 03 50 05 16 04-01 01 01 00 02 FF FF FF 0AEC:0020 FF FF FF FF FF FF FF FF-FF FF FF FF 06 05 4E 01 0AEC:0030 10 0A 14 00 18 00 EC 0A-FF FF FF FF 00 00 00 00 0AEC:0040 05 00 00 00 00 00 00 00-00 00 00 00 00 00 00 00 0AEC:0050 CD 21 CB 00 00 00 00 00-00 00 00 00 00 20 20 20 0AEC:0060 20 20 20 20 20 20 20 20-00 00 00 00 00 20 20 20 0AEC:0070 20 20 20 20 20 20 20 20-00 00 00 00 00 00 00 00 8086 端序 如何知道当前的 8086 是大端序还是小端序，可以使用下面的汇编代码测试</description>
    </item>
    
    <item>
      <title>字符集与字符编码</title>
      <link>http://example.org/os/charset/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/os/charset/</guid>
      <description>之前已经了解过一些 Unicode 和 UTF-8 之前的关系，见 UTF-8 编码及检查其完整性.md。
今天在看 ICU 文档的时候，又再一次看到 codepage 这个参数，比如 u_fopen，于是想了解一下 code page 和 character set、character encoding 之间的关系。
代码页「Code Page」，也被称为 字符编码「Character Encoding」。维基百科上还解释称代码页也被称为内码，见，初一看确认让人感觉云里雾里的，不排除中文翻译的问题。内码表示的是操作系统或者应用程序内部使用的编码，简称为「内码」。相信有人会和我一样，最初会以为代码页只的是很多编码格式的集合，单其实不是，一个代码页对应一个字符编码格式。
字符集「Character Set」，这里的集合「Set」表示的是字符与指代它们的数字之间的对应关系的集合，比如：
a_character_set = { &amp;#39;a&amp;#39;: 1, &amp;#39;b&amp;#39;: 2 } 那么字符集与字符编码有什么不同吗？区别就在于，编码引入了转换处理的过程。我们拿 Unicode 和 UTF-8 来举例。Unicode 就是字符集，我们通常可以使用 UInt32 来表示一个字符对应的 Unicode 中的数字，就好比上面的例子。而 UTF-8 被称为字符编码的原因，就是因为它包含了将原本需要 UInt32 即 4 个字节表示的字符，处理成需要 1~4 个不等的字符来表示的形式，这其中的转换就是编码的工作含义。我们甚至可以将 Character Set 理解为最简单的 Character Encoding。
如果我们打开浏览器控制台检查「Inspect」一个请求的话，会发现在 Response Headers 中有：
Content-Type: text/html; charset=UTF-8 我们发现 UTF-8 是作为 charset 的值，为什么这里不是 char-encoding 呢？这是因为 HTTP 标准制定诞生在 Unicode 标准之前，那时都是使用 Character Set 的形式，而在 Unicode 系列标准出现后，为了保证兼容性 HTTP 标准保留了 charset 的使用。</description>
    </item>
    
    <item>
      <title>静态页面</title>
      <link>http://example.org/browser/same-origin/</link>
      <pubDate>Mon, 17 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/browser/same-origin/</guid>
      <description>静态页面 在浏览器脚本的概念没有出现之前，所有的网页都是静态的。我们知道浏览器的工作模式是：
 浏览器向网站服务器发起请求 网站接受浏览器的请求，返回一些字符串（比如一些组成页面的 HTML 字符串） 浏览器接收到网站返回的用于组成页面的字符串后，就可以关闭连接了 浏览器将组成页面的字符串渲染到屏幕上，使得用户可以看到一个可视化的结果  看起来就像下面这样：
 Client Request +-------------+ +--------+ +------+ | User Agent | +--------------------------------&amp;gt; | | | User +------&amp;gt; | | Server | +--^---+ | (Browser) | &amp;lt;--------------------------------+ | | | +-------+-----+ +--------+ | | Server Response | | | | | +---------v--------+ | | Close Connection | | +---------+--------+ | | | | | +--------v--------+ ^---------+ Render response | +-----------------+ 我们看到，一旦用户代理（浏览器）关闭了和服务器之间的链接之后，客户端和服务器之间将不能继续通信。</description>
    </item>
    
    <item>
      <title>crypto-conditions 简述</title>
      <link>http://example.org/blockchain/crypto-conditions/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/blockchain/crypto-conditions/</guid>
      <description>crypto-conditions 简述  下文将 crypto-conditions 简称为 cc cc 的详细的文档描述见 ietf
 在现有的 public-key 这样的签名策略下，消息的传递过程如下:
 消息发送方 A 先将需要发送给消息接受方 B 的消息 M 进行摘要 H = hash(M) A 用自己的私钥对摘要进行加密得到 AEH (A&amp;rsquo;s encrypted hash 即 signature) A 将要发送的消息 M 以及签名 AEH 发送给 B B 接受到 M 后，对 M 进行摘要得到 BH B 使用 A 的公钥对 AEH 进行解密，得到 AH B 通过判断 BH == AH 是否成立来确定消息是否来自于 A  可以看到在 public-key 策略下，对一个消息的合法性的校验，发送方被限制成了单个实体 (one keypair)、单个条件 (签名匹配)
而 cc，则提供一个将现有加密验证算法进行条件组合的功能，比如上面的例子是 A 给 B 发送了消息，B 希望验证这个消息是 A 发送的。通过 cc，可以实现 A、C、D 一起给 B 发送了一个消息，B 可以验证 A、C、D 一起发送的，又或者 A、C、D 一起给 B 发送了一个消息，同时告诉 B，它们之间只要确定两个人，就可以证明消息的正确性，那么当 B 验证时，只要确保三人之间通过两人即可。</description>
    </item>
    
    <item>
      <title>实用拜占庭容错简介</title>
      <link>http://example.org/blockchain/practical-byzantine-fault-tolerance/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/blockchain/practical-byzantine-fault-tolerance/</guid>
      <description>实用拜占庭容错简介 容错性一直是分布式系统中需要处理的问题，而拜占庭将军问题被认为是容错性问题中最难的问题类型之一。分布式账本作为一个分布式系统，也面临该问题，著名的比特币则是采用的 PoW 来应对该问题，类似的还有以太坊中的 PoS 等。本文则简单介绍了另一种解决方案，即实用拜占庭容错算法(Practical Byzantine Fault Tolerance) 该算法的衍生版本也在一些分布式账本系统中得到应用，比如 Neo。
关于拜占庭将军问题的简单描述如下：
 一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。因为各位将军分处城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同的投票结果而决定行动策略。
 以上内容摘自 维基百科-拜占庭将军问题。
在早期 1982 年的论文中提出的算法，并不具备非常高的实用性。因为为了达成共识，节点需要观察其余节点对消息的反应，这就需要消息需要以一个类似“递归”的形式在不同的轮次中的各个节点间传递。如果需要进一步了解其中的细节，除了参考论文实现外，还可以参考这篇文章 Mark Nelson - The Byzantine Generals Problem 。
而实用拜占庭容错算法，则提供了一个相对于早期算法而言，更易于实现、更高效的算法。
实用拜占庭容错算法，其实是将拜占庭将军问题简化成以下两点来考虑：
 系统中的消息，存在不可达的可能性，由于网络问题，软件自身错误等，简称 fail-stop 系统中可能存在恶意节点，故意破坏系统的一致性，简称 malicious  当系统只存在问题 1 时，该问题的其实就回到类似内网中的节点同步问题。Viewstamped Replication 或者 paxos 等算法都提供了对该问题的解决方案。而实用拜占庭容错算法，实际是在 Viewstamped Replication 算法上的升级、额外提供了对问题 2 的解决方案。
实用拜占庭容错算法，可以粗略的描述为：
在实用拜占庭容错算法中，将每次的共识称之为 view，在每次共识中，都会选择其中一个节点作为 primary，其余节点为 backups。每次的共识，即 view 都有一个自增的 id。当次 view 中的 primary 的选取规则为 P = v mod |R| v 表示 view id，|R| 表示节点总数，R 为 replica 的简写。</description>
    </item>
    
    <item>
      <title>加密算法调研</title>
      <link>http://example.org/crypto/brief-crypto/</link>
      <pubDate>Thu, 13 Jun 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/crypto/brief-crypto/</guid>
      <description>加密算法调研 需求需要对数据进行加解密，所以需要对一些常见加密算法做一些调研。
对称加密 对称加密 Symmetric-key algorithms 有如下几个特点：
 使用相同的密匙进行加解密 加解密速度相比非对称加密要快 对 plaintext 的大小理论上没有限制 加密后的密文大小的增幅不大  非对称加密 非对称加密 Public-key cryptography, or asymmetric cryptography 有如下几个特点
 使用一个公私匙对进行加解密 加密速度相比对称加密要慢很多 在特定情况下，对 plaintext 的大小有限制 加密后的密文大小的增幅很大  常见的非对称加密算法有：
 RSA (HTTPS 中使用) ECDSA (Bitcoin 中使用)  RSA 和 ECDSA 的比较可以参考 ECDSA and RSA，简单的来说 ECDSA 有如下几个优点
 在与 RSA 达到相同加密程度下的 key 尺寸更小 见 Elliptic_Curve_Cryptography 在与 RSA 达到相同加密程度下的 key 生成更快 加解密比 RSA 快点  RSA 的加密程度与 key 的大小成正比。</description>
    </item>
    
    <item>
      <title>魔数 0x7c00</title>
      <link>http://example.org/os/0x7c00/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/os/0x7c00/</guid>
      <description>魔数 0x7c00 在涉及到计算机系统引导部分的内容时，经常会看到这个魔数(maigc number) 0x7c00。
找到一篇文章讲述这个魔数的来龙去脉 Why BIOS loads MBR into 0x7C00 in x86 ，简单地小结下文中的内容:
  0x7c00 这个魔数和 CPU 没有直接关系，并不属于 CPU 手册中的规定内容
  它第一次出现在 IBM PC 5150 ROM BIOS INT 19h handler，就是 IBM PC 5150 基础输入输出系统中的第19个中断处理句柄中
  之所以在 CPU 手册中没有任何关于 0x7c00 的细节，是因为它完全是属于 BIOS 的规格参数。
  来自 IBM PC 5150 开发团队的解释是：
 他们在设计系统时以内存最小为 32KiB 为目标 他们希望在 32KiB 之内流出更多的空间给 OS 来完成自身的引导 8086/8088 使用 0x0-0x3FF 来存放中断矢量，紧随其后的是 BIOS 的数据段 引导扇区(boot sector) 是 512字节，并且引导引导程序的栈大小为 512字节 所以 BIOS 将引导程序载入到 0x7c00 位置，引导程序将使用 32KiB 的最后 1024B 的内容  在 OS 载入完成后，引导扇区在内存中占据的内容将不再被使用，因此 OS 和应用程序可是使用这块内存。在 OS 载入后，内存中的情形类似:</description>
    </item>
    
    <item>
      <title>为什么需要检查 UTF-8 编码</title>
      <link>http://example.org/os/utf8-encoding/</link>
      <pubDate>Thu, 07 Mar 2019 00:00:00 +0800</pubDate>
      
      <guid>http://example.org/os/utf8-encoding/</guid>
      <description>为什么需要检查 UTF-8 编码 根据 WebSocket 协议的要求 5.6 数据帧，如果 Frame 的 Opcode 是 0x1 的话，则表示这是一个文本帧，即其 “Application Data” 是使用 UTF-8 编码的字符串。不过由于消息也可以使用多个 Frame 进行分片传输，所以在验证文本消息的编码时，需要收集到消息的所有 Frames 后，提取所有的 Frame 中的 “Application Data” 组成一个大的 “Application Data”，然后验证这个大的 “Application Data” 中的字节是不是合法的 UTF-8 编码。
既然协议中要求了文本消息必须使用 UTF-8 编码，那么反过来，验证编码是否是 UTF-8就可以一定程度上确定消息的完整性。
Unicode 简单的说 Unicode 就是一种字符的编码方式，此编码方式一般使用两个字节（UCS-2）去表示一个字符，比如“汉”这个中文字符，其 unicode 编码的十六进制表示就是 0x6c49。
UTF-8 UTF-8 的全称是 8-bit Unicode Transformation Format 中文就是 “8 位的 unicode 转换格式”。UTF-8 是具体的 Unicode 实现方式中的一种，套用 wiki 上的一段话：
 但是在实际传输过程中，由于不同系统平台的设计不一定一致，以及出于节省空间的目的，对Unicode编码的实现方式有所不同。Unicode的实现方式称为Unicode转换格式（Unicode Transformation Format，简称为UTF）
 UTF-8 的编码方式  UTF-8使用一至六个字节为每个字符编码（尽管如此，2003年11月UTF-8被RFC 3629重新规范，只能使用原来Unicode定义的区域，U+0000到U+10FFFF，也就是说最多四个字节）</description>
    </item>
    
  </channel>
</rss>
